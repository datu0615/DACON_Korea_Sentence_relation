{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2687,"status":"ok","timestamp":1646037888060,"user":{"displayName":"장준보","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1wOQ7PGKpBDsWEmPjG2rFr7idPoKgnOwi5x4h=s64","userId":"12796992458142872403"},"user_tz":-540},"id":"ltroKKTXdwlY","outputId":"c5285d45-aac1-4f5c-b8a4-c3aa5caae113"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3391,"status":"ok","timestamp":1646037891446,"user":{"displayName":"장준보","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1wOQ7PGKpBDsWEmPjG2rFr7idPoKgnOwi5x4h=s64","userId":"12796992458142872403"},"user_tz":-540},"id":"FEAqN-r2d0nM","outputId":"01877e98-a695-4ecf-a2f1-fb7b770bf922"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.16.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n","Requirement already satisfied: tokenizers!=0.11.3,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.5)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.47)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tbt7mQzTd4Ff"},"outputs":[],"source":["import pandas as pd \n","import numpy as np \n","import os\n","import torch\n","import torch.nn as nn\n","\n","import warnings \n","warnings.filterwarnings(\"ignore\")\n","from tqdm import tqdm\n","from torch.nn import functional as F\n","from torch.utils.data import DataLoader, Dataset\n","from transformers import AutoModel,AutoTokenizer,RobertaTokenizer, ElectraForSequenceClassification, AdamW, ElectraModel,ElectraTokenizer\n","from transformers.optimization import get_cosine_schedule_with_warmup, get_linear_schedule_with_warmup\n","import re\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HFjgPSh8E0H_"},"outputs":[],"source":["# Random Seed Fix\n","import random\n","def seed_everything(seed: int = 42):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)  \n","    torch.backends.cudnn.deterministic = True  \n","    torch.backends.cudnn.benchmark = True  \n","seed_everything()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u5VAv2AlE6zn"},"outputs":[],"source":["device = torch.device(\"cuda\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O1xjHfahF8u3"},"outputs":[],"source":["############# HYPERPARMS ##############\n","num_epochs = 5\n","batch_size =128\n","lr = 0.00001\n","pretrain = \"roberta-large\"\n","#pretrain = \"roberta-base\""]},{"cell_type":"code","source":["def load_data(path):\n","  TRAIN = os.path.join(path, 'train_data.csv')\n","  TEST = os.path.join(path, 'test_data.csv')\n","  SS = os.path.join(path, 'sample_submission.csv')\n","  label_dict = {\"entailment\" : 0, \"contradiction\" : 1, \"neutral\" : 2}\n","  train = pd.read_csv(TRAIN)\n","  test = pd.read_csv(TEST)\n","  sample_submission = pd.read_csv(SS)\n","  train['label'] = train['label'].map(label_dict)\n","\n","  return train,test,sample_submission\n","\n","def text_clean(df):\n","  #=df[\"premise_\"] = \"<s>\" + df[\"premise\"].astype(str) + \"[SEP]\"\n","  df[\"premise_\"] = \"[CLS]\"+df[\"premise\"].astype(str)\n","  #df[\"hypothesis_\"] = df[\"hypothesis\"].astype(str) + \"[SEP]\"\n","  df[\"hypothesis_\"] = df[\"hypothesis\"].astype(str) + \"[SEP]\"\n","  df[\"text_sum\"] = df.premise_ + \"[SEP]\" + df.hypothesis_\n","  df = df[['text_sum','label']]\n","  return df \n","\n","def random_deletion(sentence, p=0.2):\n","    words = sentence.split ()\n","    n = len (words)\n","    if n == 1: # return if single word\n","        return words\n","    remaining = list(filter(lambda x: random.uniform(0,1) > p,words))\n","    #print (remaining) \n","    if len(remaining) == 0: # if not left, sample a random word\n","        return ' '.join ([random.choice(words)])\n","    else:\n","        return ' '.join (remaining)\n","\n","def random_swap(sentence, n=2):\n","    sentence = sentence.split () \n","    length = range(len(sentence))\n","    swapped = []\n","    if len(sentence) >2:\n","      for _ in range(n):\n","          idx1, idx2 = random.sample(length, 2)\n","          swapped.append ([sentence[idx1], sentence[idx2]])\n","          sentence[idx1], sentence[idx2] = sentence[idx2], sentence[idx1] \n","    return ' '.join (sentence)\n","\n","def eda_aug(df):\n","\n","    cache = {'premise':[], 'hypothesis':[], 'label':[]}\n","    for idx in tqdm(range(len(df))):\n","        premise = df.iloc[idx]['premise']\n","        hypothesis = df.iloc[idx]['hypothesis']\n","        label = df.iloc[idx]['label']\n","        cache['premise'].append(premise)\n","        cache['hypothesis'].append(hypothesis)\n","        cache['label'].append(label)\n","        flag = random.randrange(10)\n","        if flag < 2:\n","          cache['premise'].append(random_deletion(premise))\n","          cache['hypothesis'].append(random_deletion(hypothesis))\n","          cache['label'].append(label)\n","          cache['premise'].append(random_swap(premise))\n","          cache['hypothesis'].append(random_swap(hypothesis))\n","          cache['label'].append(label)\n","    \n","    return pd.DataFrame(cache)"],"metadata":{"id":"gFLdEkBcjXfU"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":676,"status":"ok","timestamp":1646037897481,"user":{"displayName":"장준보","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1wOQ7PGKpBDsWEmPjG2rFr7idPoKgnOwi5x4h=s64","userId":"12796992458142872403"},"user_tz":-540},"id":"UH2mpAvEGGjH","colab":{"base_uri":"https://localhost:8080/","height":830},"outputId":"711ceb79-6914-44c5-f816-de46d31b0fe7"},"outputs":[{"output_type":"display_data","data":{"text/html":["\n","  <div id=\"df-406f7b7f-54f7-4e7b-bf70-5582b286ab71\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text_sum</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>[CLS]씨름은 상고시대로부터 전해져 내려오는 남자들의 대표적인 놀이로서, 소년이나...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>[CLS]삼성은 자작극을 벌인 2명에게 형사 고소 등의 법적 대응을 검토 중이라고 ...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>[CLS]이를 위해 예측적 범죄예방 시스템을 구축하고 고도화한다.[SEP]예측적 범...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>[CLS]광주광역시가 재개발 정비사업 원주민들에 대한 종합대책을 마련하는 등 원주민...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>[CLS]진정 소비자와 직원들에게 사랑 받는 기업으로 오래 지속되고 싶으면, 이런 ...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>24993</th>\n","      <td>[CLS]오페라에 비하여 오라토리오에서는 독창보다도 합창이 중시되며, 테스토 또는 ...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>24994</th>\n","      <td>[CLS]지하철역까지 걸어서 5분 정도 걸립니다.[SEP]지하철역까지 도보로 5분 ...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>24995</th>\n","      <td>[CLS]한편 이날 중앙방역대책본부는 집단 감염이 발생한 음식점 관련 역학조사 결과...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>24996</th>\n","      <td>[CLS]마미손이 랩을 하자 시청자들은 그의 정체를 파악했다.[SEP]시청자들은 마...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>24997</th>\n","      <td>[CLS]집근처에 지하철역,버스정류장이 있기때문에 다른 곳으로 이동하는데 좋았습니다...</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>24998 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-406f7b7f-54f7-4e7b-bf70-5582b286ab71')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-406f7b7f-54f7-4e7b-bf70-5582b286ab71 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-406f7b7f-54f7-4e7b-bf70-5582b286ab71');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                                text_sum  label\n","0      [CLS]씨름은 상고시대로부터 전해져 내려오는 남자들의 대표적인 놀이로서, 소년이나...      1\n","1      [CLS]삼성은 자작극을 벌인 2명에게 형사 고소 등의 법적 대응을 검토 중이라고 ...      1\n","2      [CLS]이를 위해 예측적 범죄예방 시스템을 구축하고 고도화한다.[SEP]예측적 범...      0\n","3      [CLS]광주광역시가 재개발 정비사업 원주민들에 대한 종합대책을 마련하는 등 원주민...      2\n","4      [CLS]진정 소비자와 직원들에게 사랑 받는 기업으로 오래 지속되고 싶으면, 이런 ...      2\n","...                                                  ...    ...\n","24993  [CLS]오페라에 비하여 오라토리오에서는 독창보다도 합창이 중시되며, 테스토 또는 ...      2\n","24994  [CLS]지하철역까지 걸어서 5분 정도 걸립니다.[SEP]지하철역까지 도보로 5분 ...      0\n","24995  [CLS]한편 이날 중앙방역대책본부는 집단 감염이 발생한 음식점 관련 역학조사 결과...      1\n","24996  [CLS]마미손이 랩을 하자 시청자들은 그의 정체를 파악했다.[SEP]시청자들은 마...      0\n","24997  [CLS]집근처에 지하철역,버스정류장이 있기때문에 다른 곳으로 이동하는데 좋았습니다...      2\n","\n","[24998 rows x 2 columns]"]},"metadata":{}},{"output_type":"display_data","data":{"text/html":["\n","  <div id=\"df-c988f084-e53b-479d-af14-885f33dc20f8\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text_sum</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>[CLS]다만 조금 좁아서 케리어를 펼치기 불편합니다.[SEP]케리어를 펼치기에 공...</td>\n","      <td>answer</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>[CLS]그리고 위치가 시먼역보다는 샤오난먼역에 가까워요[SEP]시먼역보다는 샤오난...</td>\n","      <td>answer</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>[CLS]구구절절 설명하고 이해시키려는 노력이 큰 의미없이 다가온다.[SEP]무엇인...</td>\n","      <td>answer</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>[CLS]몇 번을 다시봐도 볼 때마다 가슴이 저민다.[SEP]다시 봤을때는 무덤덤했...</td>\n","      <td>answer</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>[CLS]8월 중에 입주신청을 하면 청년은 9월, 신혼부부는 10월부터 입주가 가능...</td>\n","      <td>answer</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1661</th>\n","      <td>[CLS]또 작업자의 숙련도와 경험 향상, 전문성을 요구하는 난이도 높은 데이터 가...</td>\n","      <td>answer</td>\n","    </tr>\n","    <tr>\n","      <th>1662</th>\n","      <td>[CLS]결말을 보니 아무래도 이 영화는 2부가 계획된 듯 합니다.[SEP]결말을 ...</td>\n","      <td>answer</td>\n","    </tr>\n","    <tr>\n","      <th>1663</th>\n","      <td>[CLS]사회적 거리 두기 상황에서 총리도 카페를 갔다가 자리가 없어서 퇴짜 맞은 ...</td>\n","      <td>answer</td>\n","    </tr>\n","    <tr>\n","      <th>1664</th>\n","      <td>[CLS]로마에서 3박4일간 이곳에서 머물렀습니다.[SEP]이곳에서 머무르며 로마의...</td>\n","      <td>answer</td>\n","    </tr>\n","    <tr>\n","      <th>1665</th>\n","      <td>[CLS]난 당신이 떠날때 길 하나도 못 건넜는데[SEP]난 당신이 떤나 사실도 모...</td>\n","      <td>answer</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1666 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c988f084-e53b-479d-af14-885f33dc20f8')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c988f084-e53b-479d-af14-885f33dc20f8 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c988f084-e53b-479d-af14-885f33dc20f8');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                                               text_sum   label\n","0     [CLS]다만 조금 좁아서 케리어를 펼치기 불편합니다.[SEP]케리어를 펼치기에 공...  answer\n","1     [CLS]그리고 위치가 시먼역보다는 샤오난먼역에 가까워요[SEP]시먼역보다는 샤오난...  answer\n","2     [CLS]구구절절 설명하고 이해시키려는 노력이 큰 의미없이 다가온다.[SEP]무엇인...  answer\n","3     [CLS]몇 번을 다시봐도 볼 때마다 가슴이 저민다.[SEP]다시 봤을때는 무덤덤했...  answer\n","4     [CLS]8월 중에 입주신청을 하면 청년은 9월, 신혼부부는 10월부터 입주가 가능...  answer\n","...                                                 ...     ...\n","1661  [CLS]또 작업자의 숙련도와 경험 향상, 전문성을 요구하는 난이도 높은 데이터 가...  answer\n","1662  [CLS]결말을 보니 아무래도 이 영화는 2부가 계획된 듯 합니다.[SEP]결말을 ...  answer\n","1663  [CLS]사회적 거리 두기 상황에서 총리도 카페를 갔다가 자리가 없어서 퇴짜 맞은 ...  answer\n","1664  [CLS]로마에서 3박4일간 이곳에서 머물렀습니다.[SEP]이곳에서 머무르며 로마의...  answer\n","1665  [CLS]난 당신이 떠날때 길 하나도 못 건넜는데[SEP]난 당신이 떤나 사실도 모...  answer\n","\n","[1666 rows x 2 columns]"]},"metadata":{}}],"source":["#ROOT = '/content/drive/MyDrive/DACON_MONTHLYNLI'\n","DATA = '/content/drive/MyDrive/DACON/sentence_relation/'\n","train,test,sample_submission = load_data(DATA)\n","###### AUGMENTATION ######\n","#train = eda_aug(train)\n","###### AUGMENTATION ######\n","\n","clean_train,clean_test  = text_clean(train),text_clean(test)\n","display(clean_train)\n","display(clean_test)"]},{"cell_type":"code","source":["model_roberta = AutoModel.from_pretrained(\"klue/roberta-large\")\n","tokenizer_roberta = AutoTokenizer.from_pretrained(\"klue/roberta-large\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DcLvSFVxitbK","executionInfo":{"status":"ok","timestamp":1646037915910,"user_tz":-540,"elapsed":18434,"user":{"displayName":"장준보","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1wOQ7PGKpBDsWEmPjG2rFr7idPoKgnOwi5x4h=s64","userId":"12796992458142872403"}},"outputId":"0c9df48e-bd20-4b88-8ca1-af98c1a7c6e6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at klue/roberta-large were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","Some weights of the model checkpoint at monologg/koelectra-base-v3-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight']\n","- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}]},{"cell_type":"code","source":["def roberta_transform(text):\n","  transform = tokenizer_roberta(text,\n","                                pad_to_max_length=True,\n","                               truncation=True,\n","                               max_length=256,\n","                               return_tensors='pt',\n","                                add_special_tokens=False)\n","  return transform"],"metadata":{"id":"DT9keH2aimO_"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sHvnbUVQKXRr"},"outputs":[],"source":["class customDataset(Dataset):\n","  def __init__(self,dataset,mode='train',transform=roberta_transform):\n","    super(customDataset, self).__init__()\n","    self.mode = mode\n","    self.dataset = dataset.reset_index(drop=True)\n","    self.transform = transform\n","\n","  def __getitem__(self, idx):\n","    \n","    text = self.dataset['text_sum'][idx]\n","    tokens = self.transform(text)\n","    token_ids = tokens['input_ids'][0]  # tensor of token ids\n","    attn_masks = tokens['attention_mask'][0]  # binary tensor with \"0\" for padded values and \"1\" for the other values\n","    token_type_ids = tokens['token_type_ids'][0]  # binary tensor with \"0\" for the 1st sentence tokens & \"1\" for the 2nd sentence tokens\n","\n","    if self.mode == 'test':\n","      return token_ids,attn_masks,token_type_ids\n","    else: \n","      labels = self.dataset['label'][idx]\n","      return token_ids,attn_masks,token_type_ids, labels\n","  \n","  def __len__(self):\n","    return(len(self.dataset))"]},{"cell_type":"code","source":["test_dataset = customDataset(clean_test,'test')\n","test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=0)"],"metadata":{"id":"6hfjeNfJOayd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class ROBERTaClassifier(nn.Module):\n","    def __init__(self,\n","                 bert,\n","                 hidden_size = 1024, # 768\n","                 num_classes=3,   ##클래스 수 조정##\n","                 params=None,\n","                 freeze_bert=False):\n","        super(ROBERTaClassifier, self).__init__()\n","        self.bert = bert\n","        self.freeze_bert=freeze_bert\n","\n","        if self.freeze_bert:\n","            for p in self.bert.parameters():\n","                p.requires_grad = False\n","\n","                 \n","        self.classifier = nn.Linear(hidden_size , 256)\n","        self.dropout = nn.Dropout(p=0.5)\n","        self.fc_layer1 = nn.Linear(256,128)\n","        self.fc_layer2 = nn.Linear(128,num_classes)\n","    \n","\n","    def forward(self, input_ids, attn_masks):\n","        \n","        _,pooler = self.bert(input_ids, attn_masks, return_dict=False)\n","        output1 = self.classifier(pooler)\n","        output2 = self.fc_layer1(output1)\n","        output3 = self.fc_layer2(self.dropout(output2))\n","        return (output3)"],"metadata":{"id":"Hn6p9I58iqo7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# roberta_large 모델이 가장 성능이 좋은 것으로 가정\n","\n","model = ROBERTaClassifier(model_roberta).to(device)\n","model=nn.DataParallel(model).to(device)\n","\n","\n","\n","model_ROOT1 = '/content/drive/MyDrive/DACON/sentence_relation/roberta_large_all/'\n","\n","model_PATHs = [\n","               os.path.join(model_ROOT1, 'ROBERTa_large_fold_0_9.pth'),\n","               os.path.join(model_ROOT1, 'ROBERTa_large_fold_1_9.pth'),\n","               os.path.join(model_ROOT1, 'ROBERTa_large_fold_2_6.pth'),\n","               os.path.join(model_ROOT1, 'ROBERTa_large_fold_3_6.pth'),\n","               os.path.join(model_ROOT1, 'ROBERTa_large_fold_4_6.pth'),\n","]\n","\n","preds = dict()\n","for pth in model_PATHs:\n","    currentm = model\n","    currentm.load_state_dict(torch.load(pth))\n","    currentm.eval()\n","    answer = []\n","    with torch.no_grad():\n","        for input_ids_batch, attention_masks_batch, token_type_ids in tqdm(test_loader):\n","            y_pred = currentm(input_ids_batch.to(device), attention_masks_batch.to(device)).detach().cpu().numpy()\n","            answer.extend(y_pred)\n","    preds['roberta_large'+pth[-5]] = np.array(answer )/ len(model_PATHs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vjSKFdrnf2LJ","executionInfo":{"status":"ok","timestamp":1646038060081,"user_tz":-540,"elapsed":136077,"user":{"displayName":"장준보","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1wOQ7PGKpBDsWEmPjG2rFr7idPoKgnOwi5x4h=s64","userId":"12796992458142872403"}},"outputId":"ba2ec54f-287a-4af8-ea0e-92f4830bdda8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 27/27 [00:23<00:00,  1.17it/s]\n","100%|██████████| 27/27 [00:23<00:00,  1.16it/s]\n","100%|██████████| 27/27 [00:23<00:00,  1.17it/s]\n","100%|██████████| 27/27 [00:23<00:00,  1.17it/s]\n","100%|██████████| 27/27 [00:23<00:00,  1.17it/s]\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s-KuH104hH8u","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1646038060083,"user_tz":-540,"elapsed":8,"user":{"displayName":"장준보","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi1wOQ7PGKpBDsWEmPjG2rFr7idPoKgnOwi5x4h=s64","userId":"12796992458142872403"}},"outputId":"a97d8c0d-478b-4d73-bfdd-c0b2e52cbfbf"},"outputs":[{"output_type":"stream","name":"stdout","text":["[[-1.49031782  2.75749826 -1.13626096]\n"," [-1.07753724 -1.50873011  2.4694798 ]\n"," [ 0.83935571 -1.11535782  0.51286239]\n"," ...\n"," [-1.20543426 -1.48434263  2.53717101]\n"," [-1.22868127 -1.48995227  2.54752445]\n"," [-1.21387935 -0.551312    1.69333184]]\n"]}],"source":["temp = np.zeros((1666, 3))\n","for key in preds.keys():\n","  x = preds[key]\n","  temp += x\n","temp = temp\n","print(temp)\n","softvoted_prob = pd.DataFrame(temp)\n","softvoted_pred = pd.DataFrame(np.argmax(temp, axis=1))\n","decode_map = {0 : \"entailment\" , 1 :  \"contradiction\" , 2 : \"neutral\" }\n","sample_submission['label'] = softvoted_pred\n","sample_submission['label'] = sample_submission['label'].map(decode_map)\n","# sample_submission.to_csv('./submission_maybe_final_final_final.csv', index = False)"]},{"cell_type":"code","source":["sample_submission.to_csv('/content/drive/MyDrive/DACON/sentence_relation/roberta_large_final2.csv', index=False)"],"metadata":{"id":"SMbh7xhEYoas"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"j7tFYPISYo0v"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"name":"roberta_large_inference.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}